#kafka配置
spring:
  kafka:
    bootstrap-servers: 10.32.160.174:9092
    #    listener:
    #      missing-topics-fatal: false
    #=============== provider  =======================
    producer:
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      #激活事务，所有消息发送只能在发生事务的方法内执行
      #      transaction-id-prefix: kafka_tx
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #自定义
      client-id: producer.client.id.demo
      #自定义，生产者会在ProducerBatch被填满或者等待超过LINGER_MS_CONFIG时发送
      linger-ms: 1
      #自定义，生产者空间不足时，send()被阻塞的时间，默认60s
      max-block-ms: 60000

    #=============== consumer  =======================
    consumer:
      # 指定默认消费者group id
      group-id: test-comsumer-group
      #earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      #latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      #none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: latest
      enable-auto-commit: true
      auto-commit-interval: 100
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #自定义，在使用Kafka的组管理时，用于检测消费者故障的超时
      session-timeout-ms: 10000

    #=============== 自定义topic  =======================
    topic:
      #自定义，topic名称
      name: test2
      #自定义，分区
      numPartitions: 3
      #自定义，副本
      replicationFactor: 1





